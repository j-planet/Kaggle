Todos:

- build auc into GBC

- calibrate classifier parameters (after getting the  test score into the ball park), including imputer

- cv with VW

- new and improved features



finished todos: :)

- compress transaction history (all in memory)
- compress transaction using index file (not in memory) :)
- output compressed transactions in chunk
- compress in parallel
- assess feature importance
- train and predict using compressed transactions' data :)
- very basic imputation
- logistic regression...? (didn't really workout)
- CV function
- quantile regression...?
- use the information of number of repeats somehow...
- amend offers
- amend offers without blowing up memory
- some offers are in the test set but never appeared in the training set:
    set([1221665,
         1190530,
         1221667,
         1230218,
         1221666,
         1203439,
         1220502,
         1220503,
         1221658,
         1219903,
         1219900,
         1213242,
         1221663])
     => could amending offers be the answer? i.e. replace company by the reputation of the company
- vw
- better CV: each fold contains a different offer/company/category

-------------------------------------

BUGS: :'( :'(


fixed BUGS: :D :D
- loop gets slower every time :'( => non-binary files don't support "random access". therefore, the later in the file,
    the longer file access takes